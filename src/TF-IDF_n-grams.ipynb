{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T20:21:21.557467Z",
     "start_time": "2024-02-29T20:21:21.550277500Z"
    }
   },
   "id": "31a9395a76f99a29",
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "source": [
    "Database:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b388cf46458f188"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      article_id                                              essay  emotion  \\\n0             67  really read immigrant article drowned make fee...  sadness   \n1             86  phone line suicide prevention line election al...  sadness   \n2            206  matter heritage able serve country thai herita...  neutral   \n3            290  frightening learn shark attack surfer aware ri...     fear   \n4            342  generation russian arent treated properly sort...  sadness   \n...          ...                                                ...      ...   \n1855          16  day woman winning sport many instance men spor...      joy   \n1856         158  hate isi group full hate insanity reason thing...    anger   \n1857         203  disgusting can not believe happening people pe...  disgust   \n1858         253  feel like world corrupt longer make feel anyth...  sadness   \n1859         344  weird experience many people dying enough safe...  sadness   \n\n                                                 tokens  \\\n0     ['really', 'read', 'immigrant', 'article', 'dr...   \n1     ['phone', 'line', 'suicide', 'prevention', 'li...   \n2     ['matter', 'heritage', 'able', 'serve', 'count...   \n3     ['frightening', 'learn', 'shark', 'attack', 's...   \n4     ['generation', 'russian', 'arent', 'treated', ...   \n...                                                 ...   \n1855  ['day', 'woman', 'winning', 'sport', 'many', '...   \n1856  ['hate', 'isi', 'group', 'full', 'hate', 'insa...   \n1857  ['disgusting', 'can', 'not', 'believe', 'happe...   \n1858  ['feel', 'like', 'world', 'corrupt', 'longer',...   \n1859  ['weird', 'experience', 'many', 'people', 'dyi...   \n\n                                                 1-gram  \\\n0     ['really', 'read', 'immigrant', 'article', 'dr...   \n1     ['phone', 'line', 'suicide', 'prevention', 'li...   \n2     ['matter', 'heritage', 'able', 'serve', 'count...   \n3     ['frightening', 'learn', 'shark', 'attack', 's...   \n4     ['generation', 'russian', 'arent', 'treated', ...   \n...                                                 ...   \n1855  ['day', 'woman', 'winning', 'sport', 'many', '...   \n1856  ['hate', 'isi', 'group', 'full', 'hate', 'insa...   \n1857  ['disgusting', 'can', 'not', 'believe', 'happe...   \n1858  ['feel', 'like', 'world', 'corrupt', 'longer',...   \n1859  ['weird', 'experience', 'many', 'people', 'dyi...   \n\n                                                 2-gram  \n0     ['really read', 'read immigrant', 'immigrant a...  \n1     ['phone line', 'line suicide', 'suicide preven...  \n2     ['matter heritage', 'heritage able', 'able ser...  \n3     ['frightening learn', 'learn shark', 'shark at...  \n4     ['generation russian', 'russian arent', 'arent...  \n...                                                 ...  \n1855  ['day woman', 'woman winning', 'winning sport'...  \n1856  ['hate isi', 'isi group', 'group full', 'full ...  \n1857  ['disgusting can', 'can not', 'not believe', '...  \n1858  ['feel like', 'like world', 'world corrupt', '...  \n1859  ['weird experience', 'experience many', 'many ...  \n\n[1860 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>essay</th>\n      <th>emotion</th>\n      <th>tokens</th>\n      <th>1-gram</th>\n      <th>2-gram</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>67</td>\n      <td>really read immigrant article drowned make fee...</td>\n      <td>sadness</td>\n      <td>['really', 'read', 'immigrant', 'article', 'dr...</td>\n      <td>['really', 'read', 'immigrant', 'article', 'dr...</td>\n      <td>['really read', 'read immigrant', 'immigrant a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>86</td>\n      <td>phone line suicide prevention line election al...</td>\n      <td>sadness</td>\n      <td>['phone', 'line', 'suicide', 'prevention', 'li...</td>\n      <td>['phone', 'line', 'suicide', 'prevention', 'li...</td>\n      <td>['phone line', 'line suicide', 'suicide preven...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>206</td>\n      <td>matter heritage able serve country thai herita...</td>\n      <td>neutral</td>\n      <td>['matter', 'heritage', 'able', 'serve', 'count...</td>\n      <td>['matter', 'heritage', 'able', 'serve', 'count...</td>\n      <td>['matter heritage', 'heritage able', 'able ser...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>290</td>\n      <td>frightening learn shark attack surfer aware ri...</td>\n      <td>fear</td>\n      <td>['frightening', 'learn', 'shark', 'attack', 's...</td>\n      <td>['frightening', 'learn', 'shark', 'attack', 's...</td>\n      <td>['frightening learn', 'learn shark', 'shark at...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>342</td>\n      <td>generation russian arent treated properly sort...</td>\n      <td>sadness</td>\n      <td>['generation', 'russian', 'arent', 'treated', ...</td>\n      <td>['generation', 'russian', 'arent', 'treated', ...</td>\n      <td>['generation russian', 'russian arent', 'arent...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1855</th>\n      <td>16</td>\n      <td>day woman winning sport many instance men spor...</td>\n      <td>joy</td>\n      <td>['day', 'woman', 'winning', 'sport', 'many', '...</td>\n      <td>['day', 'woman', 'winning', 'sport', 'many', '...</td>\n      <td>['day woman', 'woman winning', 'winning sport'...</td>\n    </tr>\n    <tr>\n      <th>1856</th>\n      <td>158</td>\n      <td>hate isi group full hate insanity reason thing...</td>\n      <td>anger</td>\n      <td>['hate', 'isi', 'group', 'full', 'hate', 'insa...</td>\n      <td>['hate', 'isi', 'group', 'full', 'hate', 'insa...</td>\n      <td>['hate isi', 'isi group', 'group full', 'full ...</td>\n    </tr>\n    <tr>\n      <th>1857</th>\n      <td>203</td>\n      <td>disgusting can not believe happening people pe...</td>\n      <td>disgust</td>\n      <td>['disgusting', 'can', 'not', 'believe', 'happe...</td>\n      <td>['disgusting', 'can', 'not', 'believe', 'happe...</td>\n      <td>['disgusting can', 'can not', 'not believe', '...</td>\n    </tr>\n    <tr>\n      <th>1858</th>\n      <td>253</td>\n      <td>feel like world corrupt longer make feel anyth...</td>\n      <td>sadness</td>\n      <td>['feel', 'like', 'world', 'corrupt', 'longer',...</td>\n      <td>['feel', 'like', 'world', 'corrupt', 'longer',...</td>\n      <td>['feel like', 'like world', 'world corrupt', '...</td>\n    </tr>\n    <tr>\n      <th>1859</th>\n      <td>344</td>\n      <td>weird experience many people dying enough safe...</td>\n      <td>sadness</td>\n      <td>['weird', 'experience', 'many', 'people', 'dyi...</td>\n      <td>['weird', 'experience', 'many', 'people', 'dyi...</td>\n      <td>['weird experience', 'experience many', 'many ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1860 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/train_ready_for_WS_preprocessed.csv', delimiter=';', header=0)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T20:20:08.889576500Z",
     "start_time": "2024-02-29T20:20:08.843718300Z"
    }
   },
   "id": "3164d2647f0a6aa2",
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF-IDF\n",
    "\n",
    "There are multiple ways to calculate the TF(term frequency)\n",
    "\n",
    "IDF - inverse document frequency\n",
    "- looks ar common/uncommon words - corrects for words like as, of, the etc\n",
    "- minimize the weighting of frequent terms while making infrequent terms have a higher impact.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63b8e9b038e15ab0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then I discovered that you can do all these using TfidfVectorizer that basically does everything you need"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bddcdcd7692204b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T20:20:10.173352100Z",
     "start_time": "2024-02-29T20:20:10.168804900Z"
    }
   },
   "id": "225414aa66dfc7eb",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gram1data = data['1-gram']\n",
    "\n",
    "gram1data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "396d9248bb928585",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<1860x4607 sparse matrix of type '<class 'numpy.float64'>'\n\twith 60121 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "result = tfidf.fit_transform(gram1data)\n",
    "\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T20:20:11.145926700Z",
     "start_time": "2024-02-29T20:20:11.085045700Z"
    }
   },
   "id": "52af77c3e73c8b3e",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print('\\nIDF values:')\n",
    "for ele1, ele2 in zip(feature_names, tfidf.idf_):\n",
    "    print(ele1, ':', ele2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deb3a85202c31a93",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "feature_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c574b0361ceef13",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('\\nWord indexes:')\n",
    "print(tfidf.vocabulary_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7dfcdd04f81135",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('\\ntf-idf value:')\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9decdb887d827051",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('\\ntf-idf values with word indices:')\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "for i, doc in enumerate(result):\n",
    "    for j, value in zip(doc.indices, doc.data):\n",
    "        word = feature_names[j]\n",
    "        print(f\"  (Document {i}, {word}:{j}) TFIDF {value:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eda9ce698da9315f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (1, 1)) \n",
    "tfidf_matrix = vectorizer.fit_transform(gram1data) \n",
    "scores = (tfidf_matrix.toarray()) \n",
    "print(\"\\n\\nScores : \\n\", scores) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ad7588619d955b5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "            term      tfidf\n",
      "2972     people  75.224417\n",
      "2414       like  48.953531\n",
      "246     article  44.658380\n",
      "4112      think  44.473852\n",
      "3334     really  42.489161\n",
      "4560      would  39.925188\n",
      "1538       feel  38.896431\n",
      "1201       dont  36.678049\n",
      "4111      thing  36.123191\n",
      "2324       know  35.637836\n",
      "1744        get  35.279800\n",
      "2848        one  35.078788\n",
      "2409       life  33.286272\n",
      "3324       read  32.997858\n",
      "2500       make  32.776660\n",
      "911     country  32.667335\n",
      "2737       need  32.611418\n",
      "3549        sad  29.781650\n",
      "902       could  29.499650\n",
      "1769      going  28.815638\n",
      "4142       time  27.872584\n",
      "2522       many  27.471150\n",
      "4462        way  27.400067\n",
      "1395       even  27.039836\n",
      "3809  something  26.909702\n",
      "668       child  26.785179\n",
      "4549      world  25.544072\n",
      "1505     family  25.367388\n",
      "2689       much  25.238860\n",
      "572        cant  24.718300\n"
     ]
    }
   ],
   "source": [
    "sums = tfidf_matrix.sum(axis = 0) \n",
    "processing = [] \n",
    "for col, term in enumerate(feature_names): \n",
    "    processing.append( (term, sums[0, col] )) \n",
    "ranking = pd.DataFrame(processing, columns = ['term', 'tfidf'])\n",
    "\n",
    "\n",
    "words = (ranking.sort_values('tfidf', ascending = False)) \n",
    "print (\"\\n\\nWords : \\n\", words.head(30)) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T20:20:14.956918Z",
     "start_time": "2024-02-29T20:20:14.915882300Z"
    }
   },
   "id": "8c304c66e2a032b4",
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "source": [
    "So basically, each row is a document(example text), and each column is a word from the corpus - we have 11 words for now so wooohoooo\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e0594e34c872794"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now I'm tryna make the TFIDF for 2gram work"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc4acc07e633af76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gram2data = data['2-gram']\n",
    "\n",
    "gram2data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "882a7470a0880b22",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "sparse_matrix_gram2data = vectorizer.fit_transform(gram2data)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"\\n\\nFeatures: \\n\", features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13b0703dacba2c5b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"\\n\\n Sparse Matrix : \\n\", sparse_matrix_gram2data.toarray()) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57945c47f9b97f02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (2, 2)) \n",
    "tfidf_matrix = vectorizer.fit_transform(gram2data) \n",
    "scores = (tfidf_matrix.toarray()) \n",
    "print(\"\\n\\nScores : \\n\", scores) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd26119693f76a12",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "                       term     tfidf\n",
      "94       shouldnt shouldnt  0.437595\n",
      "54               line line  0.398837\n",
      "46       heritage heritage  0.291730\n",
      "20         country country  0.291730\n",
      "59               make make  0.281221\n",
      "79   prevention prevention  0.265892\n",
      "67               need need  0.265892\n",
      "78         prevention line  0.265892\n",
      "109  thankfully thankfully  0.208047\n",
      "83           racism racism  0.145865\n",
      "28        duckworth family  0.145865\n",
      "90             serve serve  0.145865\n",
      "61         matter heritage  0.145865\n",
      "35           family family  0.145865\n",
      "36          family service  0.145865\n",
      "0                able able  0.145865\n",
      "82          racism allowed  0.145865\n",
      "81       provided provided  0.145865\n",
      "80        provided country  0.145865\n",
      "91        service provided  0.145865\n",
      "45           heritage able  0.145865\n",
      "47       heritage shouldnt  0.145865\n",
      "50            issue debate  0.145865\n",
      "51             issue issue  0.145865\n",
      "27     duckworth duckworth  0.145865\n",
      "89           serve country  0.145865\n",
      "92         service service  0.145865\n",
      "93          shouldnt issue  0.145865\n",
      "2          allowed allowed  0.145865\n",
      "3           allowed debate  0.145865\n"
     ]
    }
   ],
   "source": [
    "sums = tfidf_matrix.sum(axis = 0) \n",
    "processing = [] \n",
    "for col, term in enumerate(features): \n",
    "    processing.append( (term, sums[0, col] )) \n",
    "    \n",
    "    \n",
    "ranking = pd.DataFrame(processing, columns = ['term', 'tfidf'])\n",
    "words = (ranking.sort_values('tfidf', ascending = False)) \n",
    "print (\"\\n\\nWords : \\n\", words.head(30)) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T20:20:18.929792900Z",
     "start_time": "2024-02-29T20:20:18.897168200Z"
    }
   },
   "id": "96a5395cbbf43808",
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e8a0e79f5d5fdc7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
