{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:27:26.138825400Z",
     "start_time": "2024-03-01T13:27:26.130947800Z"
    }
   },
   "id": "31a9395a76f99a29",
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "source": [
    "Database:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b388cf46458f188"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      article_id                                              essay  emotion  \\\n0             67  really read immigrant article drowned make fee...  sadness   \n1             86  phone line suicide prevention line election al...  sadness   \n2            206  matter heritage able serve country thai herita...  neutral   \n3            290  frightening learn shark attack surfer aware ri...     fear   \n4            342  generation russian arent treated properly sort...  sadness   \n...          ...                                                ...      ...   \n1855          16  day woman winning sport many instance men spor...      joy   \n1856         158  hate isi group full hate insanity reason thing...    anger   \n1857         203  disgusting can not believe happening people pe...  disgust   \n1858         253  feel like world corrupt longer make feel anyth...  sadness   \n1859         344  weird experience many people dying enough safe...  sadness   \n\n                                                 tokens  \\\n0     ['really', 'read', 'immigrant', 'article', 'dr...   \n1     ['phone', 'line', 'suicide', 'prevention', 'li...   \n2     ['matter', 'heritage', 'able', 'serve', 'count...   \n3     ['frightening', 'learn', 'shark', 'attack', 's...   \n4     ['generation', 'russian', 'arent', 'treated', ...   \n...                                                 ...   \n1855  ['day', 'woman', 'winning', 'sport', 'many', '...   \n1856  ['hate', 'isi', 'group', 'full', 'hate', 'insa...   \n1857  ['disgusting', 'can', 'not', 'believe', 'happe...   \n1858  ['feel', 'like', 'world', 'corrupt', 'longer',...   \n1859  ['weird', 'experience', 'many', 'people', 'dyi...   \n\n                                                 1-gram  \\\n0     ['really', 'read', 'immigrant', 'article', 'dr...   \n1     ['phone', 'line', 'suicide', 'prevention', 'li...   \n2     ['matter', 'heritage', 'able', 'serve', 'count...   \n3     ['frightening', 'learn', 'shark', 'attack', 's...   \n4     ['generation', 'russian', 'arent', 'treated', ...   \n...                                                 ...   \n1855  ['day', 'woman', 'winning', 'sport', 'many', '...   \n1856  ['hate', 'isi', 'group', 'full', 'hate', 'insa...   \n1857  ['disgusting', 'can', 'not', 'believe', 'happe...   \n1858  ['feel', 'like', 'world', 'corrupt', 'longer',...   \n1859  ['weird', 'experience', 'many', 'people', 'dyi...   \n\n                                                 2-gram  \n0     ['really read', 'read immigrant', 'immigrant a...  \n1     ['phone line', 'line suicide', 'suicide preven...  \n2     ['matter heritage', 'heritage able', 'able ser...  \n3     ['frightening learn', 'learn shark', 'shark at...  \n4     ['generation russian', 'russian arent', 'arent...  \n...                                                 ...  \n1855  ['day woman', 'woman winning', 'winning sport'...  \n1856  ['hate isi', 'isi group', 'group full', 'full ...  \n1857  ['disgusting can', 'can not', 'not believe', '...  \n1858  ['feel like', 'like world', 'world corrupt', '...  \n1859  ['weird experience', 'experience many', 'many ...  \n\n[1860 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>essay</th>\n      <th>emotion</th>\n      <th>tokens</th>\n      <th>1-gram</th>\n      <th>2-gram</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>67</td>\n      <td>really read immigrant article drowned make fee...</td>\n      <td>sadness</td>\n      <td>['really', 'read', 'immigrant', 'article', 'dr...</td>\n      <td>['really', 'read', 'immigrant', 'article', 'dr...</td>\n      <td>['really read', 'read immigrant', 'immigrant a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>86</td>\n      <td>phone line suicide prevention line election al...</td>\n      <td>sadness</td>\n      <td>['phone', 'line', 'suicide', 'prevention', 'li...</td>\n      <td>['phone', 'line', 'suicide', 'prevention', 'li...</td>\n      <td>['phone line', 'line suicide', 'suicide preven...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>206</td>\n      <td>matter heritage able serve country thai herita...</td>\n      <td>neutral</td>\n      <td>['matter', 'heritage', 'able', 'serve', 'count...</td>\n      <td>['matter', 'heritage', 'able', 'serve', 'count...</td>\n      <td>['matter heritage', 'heritage able', 'able ser...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>290</td>\n      <td>frightening learn shark attack surfer aware ri...</td>\n      <td>fear</td>\n      <td>['frightening', 'learn', 'shark', 'attack', 's...</td>\n      <td>['frightening', 'learn', 'shark', 'attack', 's...</td>\n      <td>['frightening learn', 'learn shark', 'shark at...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>342</td>\n      <td>generation russian arent treated properly sort...</td>\n      <td>sadness</td>\n      <td>['generation', 'russian', 'arent', 'treated', ...</td>\n      <td>['generation', 'russian', 'arent', 'treated', ...</td>\n      <td>['generation russian', 'russian arent', 'arent...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1855</th>\n      <td>16</td>\n      <td>day woman winning sport many instance men spor...</td>\n      <td>joy</td>\n      <td>['day', 'woman', 'winning', 'sport', 'many', '...</td>\n      <td>['day', 'woman', 'winning', 'sport', 'many', '...</td>\n      <td>['day woman', 'woman winning', 'winning sport'...</td>\n    </tr>\n    <tr>\n      <th>1856</th>\n      <td>158</td>\n      <td>hate isi group full hate insanity reason thing...</td>\n      <td>anger</td>\n      <td>['hate', 'isi', 'group', 'full', 'hate', 'insa...</td>\n      <td>['hate', 'isi', 'group', 'full', 'hate', 'insa...</td>\n      <td>['hate isi', 'isi group', 'group full', 'full ...</td>\n    </tr>\n    <tr>\n      <th>1857</th>\n      <td>203</td>\n      <td>disgusting can not believe happening people pe...</td>\n      <td>disgust</td>\n      <td>['disgusting', 'can', 'not', 'believe', 'happe...</td>\n      <td>['disgusting', 'can', 'not', 'believe', 'happe...</td>\n      <td>['disgusting can', 'can not', 'not believe', '...</td>\n    </tr>\n    <tr>\n      <th>1858</th>\n      <td>253</td>\n      <td>feel like world corrupt longer make feel anyth...</td>\n      <td>sadness</td>\n      <td>['feel', 'like', 'world', 'corrupt', 'longer',...</td>\n      <td>['feel', 'like', 'world', 'corrupt', 'longer',...</td>\n      <td>['feel like', 'like world', 'world corrupt', '...</td>\n    </tr>\n    <tr>\n      <th>1859</th>\n      <td>344</td>\n      <td>weird experience many people dying enough safe...</td>\n      <td>sadness</td>\n      <td>['weird', 'experience', 'many', 'people', 'dyi...</td>\n      <td>['weird', 'experience', 'many', 'people', 'dyi...</td>\n      <td>['weird experience', 'experience many', 'many ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1860 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/train_ready_for_WS_preprocessed.csv', delimiter=';', header=0)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T09:28:59.200869Z",
     "start_time": "2024-03-01T09:28:59.158112300Z"
    }
   },
   "id": "3164d2647f0a6aa2",
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF-IDF\n",
    "\n",
    "There are multiple ways to calculate the TF(term frequency)\n",
    "\n",
    "IDF - inverse document frequency\n",
    "- looks ar common/uncommon words - corrects for words like as, of, the etc\n",
    "- minimize the weighting of frequent terms while making infrequent terms have a higher impact.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63b8e9b038e15ab0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then I discovered that you can do all these using TfidfVectorizer that basically does everything you need"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bddcdcd7692204b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0    ['really', 'read', 'immigrant', 'article', 'dr...\n1    ['phone', 'line', 'suicide', 'prevention', 'li...\n2    ['matter', 'heritage', 'able', 'serve', 'count...\n3    ['frightening', 'learn', 'shark', 'attack', 's...\n4    ['generation', 'russian', 'arent', 'treated', ...\nName: 1-gram, dtype: object"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram1data = data['1-gram'].head(5)\n",
    "\n",
    "gram1data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:27.312871Z",
     "start_time": "2024-03-01T13:30:27.308123100Z"
    }
   },
   "id": "396d9248bb928585",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<5x112 sparse matrix of type '<class 'numpy.float64'>'\n\twith 115 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "result = tfidf.fit_transform(gram1data)\n",
    "\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:27.792494100Z",
     "start_time": "2024-03-01T13:30:27.781224300Z"
    }
   },
   "id": "52af77c3e73c8b3e",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IDF values:\n",
      "able : 2.09861228866811\n",
      "afford : 2.09861228866811\n",
      "allowed : 2.09861228866811\n",
      "also : 1.6931471805599454\n",
      "anxious : 2.09861228866811\n",
      "arent : 2.09861228866811\n",
      "article : 2.09861228866811\n",
      "associated : 2.09861228866811\n",
      "attack : 2.09861228866811\n",
      "australia : 2.09861228866811\n",
      "aware : 2.09861228866811\n",
      "baby : 2.09861228866811\n",
      "barely : 2.09861228866811\n",
      "beach : 2.09861228866811\n",
      "best : 2.09861228866811\n",
      "cant : 2.09861228866811\n",
      "care : 2.09861228866811\n",
      "climbed : 2.09861228866811\n",
      "committed : 2.09861228866811\n",
      "committing : 2.09861228866811\n",
      "condition : 1.6931471805599454\n",
      "cost : 2.09861228866811\n",
      "country : 2.09861228866811\n",
      "day : 2.09861228866811\n",
      "dealt : 2.09861228866811\n",
      "debate : 2.09861228866811\n",
      "drowned : 2.09861228866811\n",
      "duckworth : 2.09861228866811\n",
      "due : 2.09861228866811\n",
      "election : 2.09861228866811\n",
      "emotional : 2.09861228866811\n",
      "enough : 2.09861228866811\n",
      "epidemic : 2.09861228866811\n",
      "establish : 2.09861228866811\n",
      "fact : 2.09861228866811\n",
      "family : 2.09861228866811\n",
      "feel : 2.09861228866811\n",
      "financial : 2.09861228866811\n",
      "financially : 2.09861228866811\n",
      "food : 2.09861228866811\n",
      "frightening : 2.09861228866811\n",
      "generation : 2.09861228866811\n",
      "get : 2.09861228866811\n",
      "good : 2.09861228866811\n",
      "happen : 2.09861228866811\n",
      "happened : 2.09861228866811\n",
      "health : 2.09861228866811\n",
      "help : 2.09861228866811\n",
      "heritage : 2.09861228866811\n",
      "immigrant : 2.09861228866811\n",
      "interest : 2.09861228866811\n",
      "involved : 2.09861228866811\n",
      "issue : 2.09861228866811\n",
      "learn : 2.09861228866811\n",
      "line : 2.09861228866811\n",
      "little : 2.09861228866811\n",
      "live : 2.09861228866811\n",
      "living : 2.09861228866811\n",
      "lost : 2.09861228866811\n",
      "make : 2.09861228866811\n",
      "matter : 2.09861228866811\n",
      "mediterranean : 2.09861228866811\n",
      "method : 2.09861228866811\n",
      "much : 2.09861228866811\n",
      "need : 2.09861228866811\n",
      "occurrence : 2.09861228866811\n",
      "ordeal : 2.09861228866811\n",
      "paying : 2.09861228866811\n",
      "people : 2.09861228866811\n",
      "per : 2.09861228866811\n",
      "permanent : 2.09861228866811\n",
      "phone : 2.09861228866811\n",
      "poor : 2.09861228866811\n",
      "precautionary : 2.09861228866811\n",
      "prevention : 2.09861228866811\n",
      "priority : 2.09861228866811\n",
      "problem : 2.09861228866811\n",
      "proper : 2.09861228866811\n",
      "properly : 2.09861228866811\n",
      "provided : 2.09861228866811\n",
      "racism : 2.09861228866811\n",
      "read : 2.09861228866811\n",
      "really : 2.09861228866811\n",
      "risk : 2.09861228866811\n",
      "russian : 2.09861228866811\n",
      "sea : 2.09861228866811\n",
      "serve : 2.09861228866811\n",
      "service : 2.09861228866811\n",
      "shark : 2.09861228866811\n",
      "shouldnt : 2.09861228866811\n",
      "solution : 2.09861228866811\n",
      "sort : 2.09861228866811\n",
      "sport : 2.09861228866811\n",
      "suicide : 2.09861228866811\n",
      "surfer : 2.09861228866811\n",
      "survivor : 2.09861228866811\n",
      "taken : 2.09861228866811\n",
      "temporary : 2.09861228866811\n",
      "terrible : 2.09861228866811\n",
      "thai : 2.09861228866811\n",
      "thankfully : 1.6931471805599454\n",
      "thought : 2.09861228866811\n",
      "treated : 2.09861228866811\n",
      "treatment : 2.09861228866811\n",
      "turn : 2.09861228866811\n",
      "type : 2.09861228866811\n",
      "upset : 2.09861228866811\n",
      "water : 2.09861228866811\n",
      "whole : 2.09861228866811\n",
      "williams : 2.09861228866811\n",
      "worse : 2.09861228866811\n",
      "would : 2.09861228866811\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print('\\nIDF values:')\n",
    "for ele1, ele2 in zip(feature_names, tfidf.idf_):\n",
    "    print(ele1, ':', ele2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:28.662326600Z",
     "start_time": "2024-03-01T13:30:28.609575500Z"
    }
   },
   "id": "deb3a85202c31a93",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['able', 'afford', 'allowed', 'also', 'anxious', 'arent', 'article',\n       'associated', 'attack', 'australia', 'aware', 'baby', 'barely',\n       'beach', 'best', 'cant', 'care', 'climbed', 'committed',\n       'committing', 'condition', 'cost', 'country', 'day', 'dealt',\n       'debate', 'drowned', 'duckworth', 'due', 'election', 'emotional',\n       'enough', 'epidemic', 'establish', 'fact', 'family', 'feel',\n       'financial', 'financially', 'food', 'frightening', 'generation',\n       'get', 'good', 'happen', 'happened', 'health', 'help', 'heritage',\n       'immigrant', 'interest', 'involved', 'issue', 'learn', 'line',\n       'little', 'live', 'living', 'lost', 'make', 'matter',\n       'mediterranean', 'method', 'much', 'need', 'occurrence', 'ordeal',\n       'paying', 'people', 'per', 'permanent', 'phone', 'poor',\n       'precautionary', 'prevention', 'priority', 'problem', 'proper',\n       'properly', 'provided', 'racism', 'read', 'really', 'risk',\n       'russian', 'sea', 'serve', 'service', 'shark', 'shouldnt',\n       'solution', 'sort', 'sport', 'suicide', 'surfer', 'survivor',\n       'taken', 'temporary', 'terrible', 'thai', 'thankfully', 'thought',\n       'treated', 'treatment', 'turn', 'type', 'upset', 'water', 'whole',\n       'williams', 'worse', 'would'], dtype=object)"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "feature_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:31.382863900Z",
     "start_time": "2024-03-01T13:30:31.342660400Z"
    }
   },
   "id": "9c574b0361ceef13",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word indexes:\n",
      "{'really': 82, 'read': 81, 'immigrant': 49, 'article': 6, 'drowned': 26, 'make': 59, 'feel': 36, 'anxious': 4, 'upset': 106, 'whole': 108, 'ordeal': 66, 'happened': 45, 'terrible': 98, 'occurrence': 65, 'happen': 44, 'mediterranean': 61, 'sea': 85, 'thankfully': 100, 'survivor': 95, 'fact': 34, 'baby': 11, 'lost': 58, 'much': 63, 'emotional': 30, 'phone': 71, 'line': 54, 'suicide': 93, 'prevention': 74, 'election': 29, 'also': 3, 'climbed': 17, 'williams': 109, 'committed': 18, 'help': 47, 'need': 64, 'thought': 101, 'condition': 20, 'people': 68, 'committing': 19, 'permanent': 70, 'solution': 90, 'temporary': 97, 'problem': 76, 'matter': 60, 'heritage': 48, 'able': 0, 'serve': 86, 'country': 22, 'thai': 99, 'shouldnt': 89, 'issue': 52, 'debate': 25, 'duckworth': 27, 'family': 35, 'service': 87, 'provided': 79, 'type': 105, 'racism': 80, 'allowed': 2, 'frightening': 40, 'learn': 53, 'shark': 88, 'attack': 8, 'surfer': 94, 'aware': 10, 'risk': 83, 'associated': 7, 'sport': 92, 'priority': 75, 'would': 111, 'best': 14, 'interest': 50, 'establish': 33, 'water': 107, 'epidemic': 32, 'dealt': 24, 'beach': 13, 'australia': 9, 'good': 43, 'precautionary': 73, 'method': 62, 'generation': 41, 'russian': 84, 'arent': 5, 'treated': 102, 'properly': 78, 'sort': 91, 'financial': 37, 'living': 57, 'little': 55, 'per': 69, 'day': 23, 'financially': 38, 'live': 56, 'poor': 72, 'paying': 67, 'barely': 12, 'enough': 31, 'food': 39, 'health': 46, 'care': 16, 'taken': 96, 'turn': 104, 'worse': 110, 'cant': 15, 'afford': 1, 'get': 42, 'proper': 77, 'treatment': 103, 'due': 28, 'cost': 21, 'involved': 51}\n"
     ]
    }
   ],
   "source": [
    "print('\\nWord indexes:')\n",
    "print(tfidf.vocabulary_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:32.277801100Z",
     "start_time": "2024-03-01T13:30:32.271795700Z"
    }
   },
   "id": "c7dfcdd04f81135",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf-idf value:\n",
      "  (0, 30)\t0.1836457753647447\n",
      "  (0, 63)\t0.1836457753647447\n",
      "  (0, 58)\t0.1836457753647447\n",
      "  (0, 11)\t0.1836457753647447\n",
      "  (0, 34)\t0.1836457753647447\n",
      "  (0, 95)\t0.1836457753647447\n",
      "  (0, 100)\t0.14816425523644533\n",
      "  (0, 85)\t0.1836457753647447\n",
      "  (0, 61)\t0.1836457753647447\n",
      "  (0, 44)\t0.1836457753647447\n",
      "  (0, 65)\t0.1836457753647447\n",
      "  (0, 98)\t0.1836457753647447\n",
      "  (0, 45)\t0.1836457753647447\n",
      "  (0, 66)\t0.1836457753647447\n",
      "  (0, 108)\t0.1836457753647447\n",
      "  (0, 106)\t0.1836457753647447\n",
      "  (0, 4)\t0.1836457753647447\n",
      "  (0, 36)\t0.1836457753647447\n",
      "  (0, 59)\t0.3672915507294894\n",
      "  (0, 26)\t0.1836457753647447\n",
      "  (0, 6)\t0.1836457753647447\n",
      "  (0, 49)\t0.1836457753647447\n",
      "  (0, 81)\t0.3672915507294894\n",
      "  (0, 82)\t0.1836457753647447\n",
      "  (1, 76)\t0.1742024183731\n",
      "  :\t:\n",
      "  (4, 110)\t0.16830668925257494\n",
      "  (4, 104)\t0.16830668925257494\n",
      "  (4, 96)\t0.16830668925257494\n",
      "  (4, 16)\t0.16830668925257494\n",
      "  (4, 46)\t0.3366133785051499\n",
      "  (4, 39)\t0.16830668925257494\n",
      "  (4, 31)\t0.16830668925257494\n",
      "  (4, 12)\t0.16830668925257494\n",
      "  (4, 67)\t0.16830668925257494\n",
      "  (4, 72)\t0.16830668925257494\n",
      "  (4, 56)\t0.16830668925257494\n",
      "  (4, 38)\t0.16830668925257494\n",
      "  (4, 23)\t0.16830668925257494\n",
      "  (4, 69)\t0.16830668925257494\n",
      "  (4, 55)\t0.16830668925257494\n",
      "  (4, 57)\t0.16830668925257494\n",
      "  (4, 37)\t0.16830668925257494\n",
      "  (4, 91)\t0.16830668925257494\n",
      "  (4, 78)\t0.16830668925257494\n",
      "  (4, 102)\t0.16830668925257494\n",
      "  (4, 5)\t0.16830668925257494\n",
      "  (4, 84)\t0.16830668925257494\n",
      "  (4, 41)\t0.16830668925257494\n",
      "  (4, 20)\t0.13578877714388676\n",
      "  (4, 3)\t0.13578877714388676\n"
     ]
    }
   ],
   "source": [
    "print('\\ntf-idf value:')\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:33.174858900Z",
     "start_time": "2024-03-01T13:30:33.132697900Z"
    }
   },
   "id": "9decdb887d827051",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf-idf values with word indices:\n",
      "  (Document 0, emotional:30) TFIDF 0.1836\n",
      "  (Document 0, much:63) TFIDF 0.1836\n",
      "  (Document 0, lost:58) TFIDF 0.1836\n",
      "  (Document 0, baby:11) TFIDF 0.1836\n",
      "  (Document 0, fact:34) TFIDF 0.1836\n",
      "  (Document 0, survivor:95) TFIDF 0.1836\n",
      "  (Document 0, thankfully:100) TFIDF 0.1482\n",
      "  (Document 0, sea:85) TFIDF 0.1836\n",
      "  (Document 0, mediterranean:61) TFIDF 0.1836\n",
      "  (Document 0, happen:44) TFIDF 0.1836\n",
      "  (Document 0, occurrence:65) TFIDF 0.1836\n",
      "  (Document 0, terrible:98) TFIDF 0.1836\n",
      "  (Document 0, happened:45) TFIDF 0.1836\n",
      "  (Document 0, ordeal:66) TFIDF 0.1836\n",
      "  (Document 0, whole:108) TFIDF 0.1836\n",
      "  (Document 0, upset:106) TFIDF 0.1836\n",
      "  (Document 0, anxious:4) TFIDF 0.1836\n",
      "  (Document 0, feel:36) TFIDF 0.1836\n",
      "  (Document 0, make:59) TFIDF 0.3673\n",
      "  (Document 0, drowned:26) TFIDF 0.1836\n",
      "  (Document 0, article:6) TFIDF 0.1836\n",
      "  (Document 0, immigrant:49) TFIDF 0.1836\n",
      "  (Document 0, read:81) TFIDF 0.3673\n",
      "  (Document 0, really:82) TFIDF 0.1836\n",
      "  (Document 1, problem:76) TFIDF 0.1742\n",
      "  (Document 1, temporary:97) TFIDF 0.1742\n",
      "  (Document 1, solution:90) TFIDF 0.1742\n",
      "  (Document 1, permanent:70) TFIDF 0.1742\n",
      "  (Document 1, committing:19) TFIDF 0.1742\n",
      "  (Document 1, people:68) TFIDF 0.1742\n",
      "  (Document 1, condition:20) TFIDF 0.1405\n",
      "  (Document 1, thought:101) TFIDF 0.1742\n",
      "  (Document 1, need:64) TFIDF 0.3484\n",
      "  (Document 1, help:47) TFIDF 0.1742\n",
      "  (Document 1, committed:18) TFIDF 0.1742\n",
      "  (Document 1, williams:109) TFIDF 0.1742\n",
      "  (Document 1, climbed:17) TFIDF 0.1742\n",
      "  (Document 1, also:3) TFIDF 0.1405\n",
      "  (Document 1, election:29) TFIDF 0.1742\n",
      "  (Document 1, prevention:74) TFIDF 0.3484\n",
      "  (Document 1, suicide:93) TFIDF 0.1742\n",
      "  (Document 1, line:54) TFIDF 0.5226\n",
      "  (Document 1, phone:71) TFIDF 0.1742\n",
      "  (Document 1, thankfully:100) TFIDF 0.1405\n",
      "  (Document 2, allowed:2) TFIDF 0.1890\n",
      "  (Document 2, racism:80) TFIDF 0.1890\n",
      "  (Document 2, type:105) TFIDF 0.1890\n",
      "  (Document 2, provided:79) TFIDF 0.1890\n",
      "  (Document 2, service:87) TFIDF 0.1890\n",
      "  (Document 2, family:35) TFIDF 0.1890\n",
      "  (Document 2, duckworth:27) TFIDF 0.1890\n",
      "  (Document 2, debate:25) TFIDF 0.3780\n",
      "  (Document 2, issue:52) TFIDF 0.1890\n",
      "  (Document 2, shouldnt:89) TFIDF 0.3780\n",
      "  (Document 2, thai:99) TFIDF 0.1890\n",
      "  (Document 2, country:22) TFIDF 0.3780\n",
      "  (Document 2, serve:86) TFIDF 0.1890\n",
      "  (Document 2, able:0) TFIDF 0.1890\n",
      "  (Document 2, heritage:48) TFIDF 0.3780\n",
      "  (Document 2, matter:60) TFIDF 0.1890\n",
      "  (Document 3, method:62) TFIDF 0.1741\n",
      "  (Document 3, precautionary:73) TFIDF 0.1741\n",
      "  (Document 3, good:43) TFIDF 0.1741\n",
      "  (Document 3, australia:9) TFIDF 0.1741\n",
      "  (Document 3, beach:13) TFIDF 0.1741\n",
      "  (Document 3, dealt:24) TFIDF 0.1741\n",
      "  (Document 3, epidemic:32) TFIDF 0.1741\n",
      "  (Document 3, water:107) TFIDF 0.1741\n",
      "  (Document 3, establish:33) TFIDF 0.1741\n",
      "  (Document 3, interest:50) TFIDF 0.1741\n",
      "  (Document 3, best:14) TFIDF 0.1741\n",
      "  (Document 3, would:111) TFIDF 0.1741\n",
      "  (Document 3, priority:75) TFIDF 0.1741\n",
      "  (Document 3, sport:92) TFIDF 0.3482\n",
      "  (Document 3, associated:7) TFIDF 0.1741\n",
      "  (Document 3, risk:83) TFIDF 0.1741\n",
      "  (Document 3, aware:10) TFIDF 0.1741\n",
      "  (Document 3, surfer:94) TFIDF 0.1741\n",
      "  (Document 3, attack:8) TFIDF 0.1741\n",
      "  (Document 3, shark:88) TFIDF 0.5222\n",
      "  (Document 3, learn:53) TFIDF 0.1741\n",
      "  (Document 3, frightening:40) TFIDF 0.1741\n",
      "  (Document 4, involved:51) TFIDF 0.1683\n",
      "  (Document 4, cost:21) TFIDF 0.1683\n",
      "  (Document 4, due:28) TFIDF 0.1683\n",
      "  (Document 4, treatment:103) TFIDF 0.1683\n",
      "  (Document 4, proper:77) TFIDF 0.1683\n",
      "  (Document 4, get:42) TFIDF 0.1683\n",
      "  (Document 4, afford:1) TFIDF 0.1683\n",
      "  (Document 4, cant:15) TFIDF 0.1683\n",
      "  (Document 4, worse:110) TFIDF 0.1683\n",
      "  (Document 4, turn:104) TFIDF 0.1683\n",
      "  (Document 4, taken:96) TFIDF 0.1683\n",
      "  (Document 4, care:16) TFIDF 0.1683\n",
      "  (Document 4, health:46) TFIDF 0.3366\n",
      "  (Document 4, food:39) TFIDF 0.1683\n",
      "  (Document 4, enough:31) TFIDF 0.1683\n",
      "  (Document 4, barely:12) TFIDF 0.1683\n",
      "  (Document 4, paying:67) TFIDF 0.1683\n",
      "  (Document 4, poor:72) TFIDF 0.1683\n",
      "  (Document 4, live:56) TFIDF 0.1683\n",
      "  (Document 4, financially:38) TFIDF 0.1683\n",
      "  (Document 4, day:23) TFIDF 0.1683\n",
      "  (Document 4, per:69) TFIDF 0.1683\n",
      "  (Document 4, little:55) TFIDF 0.1683\n",
      "  (Document 4, living:57) TFIDF 0.1683\n",
      "  (Document 4, financial:37) TFIDF 0.1683\n",
      "  (Document 4, sort:91) TFIDF 0.1683\n",
      "  (Document 4, properly:78) TFIDF 0.1683\n",
      "  (Document 4, treated:102) TFIDF 0.1683\n",
      "  (Document 4, arent:5) TFIDF 0.1683\n",
      "  (Document 4, russian:84) TFIDF 0.1683\n",
      "  (Document 4, generation:41) TFIDF 0.1683\n",
      "  (Document 4, condition:20) TFIDF 0.1358\n",
      "  (Document 4, also:3) TFIDF 0.1358\n"
     ]
    }
   ],
   "source": [
    "print('\\ntf-idf values with word indices:')\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "for i, doc in enumerate(result):\n",
    "    for j, value in zip(doc.indices, doc.data):\n",
    "        word = feature_names[j]\n",
    "        print(f\"  (Document {i}, {word}:{j}) TFIDF {value:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:34.123075700Z",
     "start_time": "2024-03-01T13:30:34.085515600Z"
    }
   },
   "id": "eda9ce698da9315f",
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores : \n",
      " [[0.         0.         0.         0.         0.18364578 0.\n",
      "  0.18364578 0.         0.         0.         0.         0.18364578\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18364578 0.         0.         0.\n",
      "  0.18364578 0.         0.         0.         0.18364578 0.\n",
      "  0.18364578 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18364578 0.18364578 0.         0.\n",
      "  0.         0.18364578 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18364578 0.36729155\n",
      "  0.         0.18364578 0.         0.18364578 0.         0.18364578\n",
      "  0.18364578 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.36729155 0.18364578 0.\n",
      "  0.         0.18364578 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18364578\n",
      "  0.         0.         0.18364578 0.         0.14816426 0.\n",
      "  0.         0.         0.         0.         0.18364578 0.\n",
      "  0.18364578 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.14054541 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.17420242\n",
      "  0.17420242 0.17420242 0.14054541 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.17420242\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.17420242\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.52260726 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.34840484 0.\n",
      "  0.         0.         0.17420242 0.         0.17420242 0.17420242\n",
      "  0.         0.         0.34840484 0.         0.17420242 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17420242 0.         0.         0.17420242 0.         0.\n",
      "  0.         0.17420242 0.         0.         0.14054541 0.17420242\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17420242 0.         0.        ]\n",
      " [0.18898224 0.         0.18898224 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.37796447 0.\n",
      "  0.         0.37796447 0.         0.18898224 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18898224\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37796447 0.         0.         0.         0.18898224 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18898224 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18898224 0.18898224 0.         0.         0.\n",
      "  0.         0.         0.18898224 0.18898224 0.         0.37796447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.18898224 0.         0.\n",
      "  0.         0.         0.         0.18898224 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17407766 0.17407766 0.17407766 0.17407766 0.\n",
      "  0.         0.17407766 0.17407766 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17407766 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17407766 0.17407766 0.         0.\n",
      "  0.         0.         0.         0.         0.17407766 0.\n",
      "  0.         0.17407766 0.         0.         0.         0.\n",
      "  0.         0.         0.17407766 0.         0.         0.17407766\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17407766 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17407766 0.         0.17407766 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.17407766\n",
      "  0.         0.         0.         0.         0.52223297 0.\n",
      "  0.         0.         0.34815531 0.         0.17407766 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.17407766\n",
      "  0.         0.         0.         0.17407766]\n",
      " [0.         0.16830669 0.         0.13578878 0.         0.16830669\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16830669 0.         0.         0.16830669 0.16830669 0.\n",
      "  0.         0.         0.13578878 0.16830669 0.         0.16830669\n",
      "  0.         0.         0.         0.         0.16830669 0.\n",
      "  0.         0.16830669 0.         0.         0.         0.\n",
      "  0.         0.16830669 0.16830669 0.16830669 0.         0.16830669\n",
      "  0.16830669 0.         0.         0.         0.33661338 0.\n",
      "  0.         0.         0.         0.16830669 0.         0.\n",
      "  0.         0.16830669 0.16830669 0.16830669 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16830669 0.         0.16830669 0.         0.\n",
      "  0.16830669 0.         0.         0.         0.         0.16830669\n",
      "  0.16830669 0.         0.         0.         0.         0.\n",
      "  0.16830669 0.         0.         0.         0.         0.\n",
      "  0.         0.16830669 0.         0.         0.         0.\n",
      "  0.16830669 0.         0.         0.         0.         0.\n",
      "  0.16830669 0.16830669 0.16830669 0.         0.         0.\n",
      "  0.         0.         0.16830669 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (1, 1)) \n",
    "tfidf_matrix = vectorizer.fit_transform(gram1data) \n",
    "scores = (tfidf_matrix.toarray()) \n",
    "print(\"\\n\\nScores : \\n\", scores) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:34.870945400Z",
     "start_time": "2024-03-01T13:30:34.856450100Z"
    }
   },
   "id": "8ad7588619d955b5",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "            term     tfidf\n",
      "54         line  0.522607\n",
      "88        shark  0.522233\n",
      "89     shouldnt  0.377964\n",
      "25       debate  0.377964\n",
      "48     heritage  0.377964\n",
      "22      country  0.377964\n",
      "81         read  0.367292\n",
      "59         make  0.367292\n",
      "64         need  0.348405\n",
      "74   prevention  0.348405\n",
      "92        sport  0.348155\n",
      "46       health  0.336613\n",
      "100  thankfully  0.288710\n",
      "3          also  0.276334\n",
      "20    condition  0.276334\n",
      "60       matter  0.188982\n",
      "80       racism  0.188982\n",
      "79     provided  0.188982\n",
      "86        serve  0.188982\n",
      "87      service  0.188982\n",
      "35       family  0.188982\n",
      "52        issue  0.188982\n",
      "27    duckworth  0.188982\n",
      "0          able  0.188982\n",
      "2       allowed  0.188982\n",
      "105        type  0.188982\n",
      "99         thai  0.188982\n",
      "45     happened  0.183646\n",
      "82       really  0.183646\n",
      "65   occurrence  0.183646\n"
     ]
    }
   ],
   "source": [
    "sums = tfidf_matrix.sum(axis = 0) \n",
    "processing = [] \n",
    "for col, term in enumerate(feature_names): \n",
    "    processing.append( (term, sums[0, col] )) \n",
    "ranking = pd.DataFrame(processing, columns = ['term', 'tfidf'])\n",
    "\n",
    "\n",
    "words = (ranking.sort_values('tfidf', ascending = False)) \n",
    "print (\"\\n\\nWords : \\n\", words.head(30)) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:30:46.253361800Z",
     "start_time": "2024-03-01T13:30:46.229499400Z"
    }
   },
   "id": "8c304c66e2a032b4",
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "words.to_csv('../data/TFIDF_values_ranking_1gram.csv', sep=';', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T09:30:03.375259Z",
     "start_time": "2024-03-01T09:30:03.240131Z"
    }
   },
   "id": "e75a70774866e3a2",
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": [
    "So basically, each row is a document(example text), and each column is a word from the corpus - we have 11 words for now so wooohoooo\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e0594e34c872794"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now I'm tryna make the TFIDF for 2gram work"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc4acc07e633af76"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0       really read immigrant article drowned make fee...\n1       phone line suicide prevention line election al...\n2       matter heritage able serve country thai herita...\n3       frightening learn shark attack surfer aware ri...\n4       generation russian arent treated properly sort...\n                              ...                        \n1855    day woman winning sport many instance men spor...\n1856    hate isi group full hate insanity reason thing...\n1857    disgusting can not believe happening people pe...\n1858    feel like world corrupt longer make feel anyth...\n1859    weird experience many people dying enough safe...\nName: essay, Length: 1860, dtype: object"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2data = data['essay']\n",
    "gram2data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:54:13.116758500Z",
     "start_time": "2024-03-01T17:54:13.103574600Z"
    }
   },
   "id": "882a7470a0880b22",
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Features: \n",
      " ['abducted killed' 'abducted tortured' 'ability able' ...\n",
      " 'zookeepers shoot' 'zulyatu alone' 'zulyatu younger']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "sparse_matrix_gram2data = vectorizer.fit_transform(gram2data)\n",
    "sparse_matrix_gram2data\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "print(\"\\n\\nFeatures: \\n\", features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:56:30.460887800Z",
     "start_time": "2024-03-01T17:56:30.294260Z"
    }
   },
   "id": "13b0703dacba2c5b",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Sparse Matrix : \n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n Sparse Matrix : \\n\", sparse_matrix_gram2data.toarray()) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:55:57.910864800Z",
     "start_time": "2024-03-01T17:55:57.886848900Z"
    }
   },
   "id": "57945c47f9b97f02",
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scores : \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (2, 2)) \n",
    "tfidf_matrix = vectorizer.fit_transform(gram2data) \n",
    "scores = (tfidf_matrix.toarray()) \n",
    "print(\"\\n\\nScores : \\n\", scores) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:56:37.792003900Z",
     "start_time": "2024-03-01T17:56:37.632769400Z"
    }
   },
   "id": "bd26119693f76a12",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Words : \n",
      "                   term      tfidf\n",
      "37144     read article  11.900401\n",
      "15891        feel like   8.099647\n",
      "7836    climate change   7.755460\n",
      "28499      many people   7.344824\n",
      "15819         feel bad   7.298333\n",
      "6219           can not   6.543351\n",
      "40561       seems like   6.419565\n",
      "12369        dont know   6.296486\n",
      "22424          im sure   5.632561\n",
      "3158      article read   5.496051\n",
      "12415       dont think   5.163374\n",
      "37318  reading article   4.566770\n",
      "6278      cant believe   4.526481\n",
      "29395      middle east   4.516918\n",
      "6314      cant imagine   4.351114\n",
      "42616   something like   4.323222\n",
      "12222     donald trump   4.251266\n",
      "18286   global warming   4.222920\n",
      "12419  dont understand   4.211120\n",
      "49118     united state   4.160152\n",
      "28079        make feel   3.949001\n",
      "37650       really sad   3.854407\n",
      "22369          im glad   3.788906\n",
      "42907       sound like   3.755581\n",
      "46308       thing like   3.690122\n",
      "34990   police officer   3.684888\n",
      "34093     people would   3.462663\n",
      "15951       feel sorry   3.355404\n",
      "28167        make sure   3.347153\n",
      "6296         cant even   3.143560\n"
     ]
    }
   ],
   "source": [
    "sums = tfidf_matrix.sum(axis = 0) \n",
    "processing = [] \n",
    "for col, term in enumerate(features): \n",
    "    processing.append( (term, sums[0, col] )) \n",
    "    \n",
    "    \n",
    "ranking = pd.DataFrame(processing, columns = ['term', 'tfidf'])\n",
    "pairs2gram = (ranking.sort_values('tfidf', ascending = False)) \n",
    "print (\"\\n\\nWords : \\n\", pairs2gram.head(30)) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:56:39.186297500Z",
     "start_time": "2024-03-01T17:56:39.132988600Z"
    }
   },
   "id": "96a5395cbbf43808",
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pairs2gram.to_csv('../data/TFIDF_values_ranking_2gram.csv', sep=';', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T17:56:47.059475900Z",
     "start_time": "2024-03-01T17:56:46.982849700Z"
    }
   },
   "id": "405ffcc7ded1317d",
   "execution_count": 174
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e8a0e79f5d5fdc7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
