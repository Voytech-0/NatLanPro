{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.155936Z",
     "start_time": "2024-03-02T16:40:54.122592Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/wojtek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/wojtek/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wojtek/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filename = '../data/train_ready_for_WS'\n",
    "# filename = '../data/test'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.192813Z",
     "start_time": "2024-03-02T16:40:54.159422Z"
    }
   },
   "id": "f4e53c1cf7cf1cfd",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the data in csv format using pandas\n",
    "data = pd.read_csv(f\"{filename}.csv\", delimiter=';', header=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.226331Z",
     "start_time": "2024-03-02T16:40:54.195086Z"
    }
   },
   "id": "88d1d9afd52dafe8",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was bullied in school, which led to self harm, and eventually a suicide attempt. This article reminded me so much of myself, and I want to do something to put a stop this bullying. As I sit here with tears welling my eyes, now a mother, I can't imagine being in the shoes of these parents who lost their children all because other kids just can't be nice. I am so sad for these kids who saw no other way out of this mess than to just end their lives. Their pain is felt deeply in my soul, and my wish is that somehow, someday, no one else will feel that kind of pain.\n"
     ]
    }
   ],
   "source": [
    "print(data['essay'][91])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.243848Z",
     "start_time": "2024-03-02T16:40:54.230860Z"
    }
   },
   "id": "f7bfd94dfe83689a",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove numbers, punctuation and make everything lowercase\n",
    "data['essay'] = data['essay'].str.replace('\\d+', '', regex=True)\n",
    "data['essay'] = data['essay'].str.replace('[^\\w\\s]','', regex=True)\n",
    "data['essay'] = data['essay'].str.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.281733Z",
     "start_time": "2024-03-02T16:40:54.256281Z"
    }
   },
   "id": "5375d4c3a05d04bc",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i was bullied in school which led to self harm and eventually a suicide attempt this article reminded me so much of myself and i want to do something to put a stop this bullying as i sit here with tears welling my eyes now a mother i cant imagine being in the shoes of these parents who lost their children all because other kids just cant be nice i am so sad for these kids who saw no other way out of this mess than to just end their lives their pain is felt deeply in my soul and my wish is that somehow someday no one else will feel that kind of pain\n"
     ]
    }
   ],
   "source": [
    "print(data['essay'][91])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.298125Z",
     "start_time": "2024-03-02T16:40:54.266709Z"
    }
   },
   "id": "b923d04fb820f3c8",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# stopword removal\n",
    "stop = stopwords.words('english')\n",
    "data['essay'] = data['essay'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.400240Z",
     "start_time": "2024-03-02T16:40:54.272652Z"
    }
   },
   "id": "7a9a53e30836ea10",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bullied school led self harm eventually suicide attempt article reminded much want something put stop bullying sit tears welling eyes mother cant imagine shoes parents lost children kids cant nice sad kids saw way mess end lives pain felt deeply soul wish somehow someday one else feel kind pain\n"
     ]
    }
   ],
   "source": [
    "print(data['essay'][91])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.404619Z",
     "start_time": "2024-03-02T16:40:54.344782Z"
    }
   },
   "id": "25db73509d85e28f",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "data['essay'] = data['essay'].apply(lemmatize_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.539135Z",
     "start_time": "2024-03-02T16:40:54.351221Z"
    }
   },
   "id": "4f983796e1e263d6",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bullied school led self harm eventually suicide attempt article reminded much want something put stop bullying sit tear welling eye mother cant imagine shoe parent lost child kid cant nice sad kid saw way mess end life pain felt deeply soul wish somehow someday one else feel kind pain\n"
     ]
    }
   ],
   "source": [
    "print(data['essay'][91])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.541284Z",
     "start_time": "2024-03-02T16:40:54.515197Z"
    }
   },
   "id": "a232afff82150466",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove words which occur only once\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in data['essay'].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "\n",
    "# create a set of words that occur only once\n",
    "if 'test' in filename:\n",
    "    once_occurred_words = {}\n",
    "else:\n",
    "    once_occurred_words = {word for word, count in cnt.items() if count == 1}\n",
    "\n",
    "# iterate over the 'essay' column and remove the words that occur only once\n",
    "data['essay'] = data['essay'].apply(lambda x: ' '.join([word for word in x.split() if word not in once_occurred_words]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.552719Z",
     "start_time": "2024-03-02T16:40:54.530716Z"
    }
   },
   "id": "eb917c0084efc38b",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bullied school led self harm eventually suicide attempt article reminded much want something put stop bullying sit tear welling eye mother cant imagine shoe parent lost child kid cant nice sad kid saw way mess end life pain felt deeply soul wish somehow someday one else feel kind pain\n"
     ]
    }
   ],
   "source": [
    "print(data['essay'][91])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.556634Z",
     "start_time": "2024-03-02T16:40:54.538389Z"
    }
   },
   "id": "89065052f35fa2fc",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1-gram and bi-gram extraction\n",
    "# Tokenize the essays into words\n",
    "data['tokens'] = data['essay'].apply(word_tokenize)\n",
    "\n",
    "# Function to extract n-grams from a list of tokens\n",
    "def extract_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))\n",
    "\n",
    "# Extract 1-grams and 2-grams\n",
    "data['1-gram'] = data['tokens'].apply(lambda x: extract_ngrams(x, 1))\n",
    "data['2-gram'] = data['tokens'].apply(lambda x: extract_ngrams(x, 2))\n",
    "\n",
    "# Convert the n-grams to strings for easier representation\n",
    "data['1-gram'] = data['1-gram'].apply(lambda x: [' '.join(gram) for gram in x])\n",
    "data['2-gram'] = data['2-gram'].apply(lambda x: [' '.join(gram) for gram in x])\n",
    "\n",
    "# Convert the lists of n-grams to DataFrames\n",
    "data['1-gram'] = pd.DataFrame(data['1-gram'])\n",
    "data['2-gram'] = pd.DataFrame(data['2-gram'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.725178Z",
     "start_time": "2024-03-02T16:40:54.572258Z"
    }
   },
   "id": "95b3506f40cb2a54",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bullied school', 'school led', 'led self', 'self harm', 'harm eventually', 'eventually suicide', 'suicide attempt', 'attempt article', 'article reminded', 'reminded much', 'much want', 'want something', 'something put', 'put stop', 'stop bullying', 'bullying sit', 'sit tear', 'tear welling', 'welling eye', 'eye mother', 'mother cant', 'cant imagine', 'imagine shoe', 'shoe parent', 'parent lost', 'lost child', 'child kid', 'kid cant', 'cant nice', 'nice sad', 'sad kid', 'kid saw', 'saw way', 'way mess', 'mess end', 'end life', 'life pain', 'pain felt', 'felt deeply', 'deeply soul', 'soul wish', 'wish somehow', 'somehow someday', 'someday one', 'one else', 'else feel', 'feel kind', 'kind pain']\n"
     ]
    }
   ],
   "source": [
    "print(data['2-gram'][91])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.735773Z",
     "start_time": "2024-03-02T16:40:54.727126Z"
    }
   },
   "id": "b6ef59b033b56212",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save the preprocessed data\n",
    "data.to_csv(f'{filename}_preprocessed.csv', sep=';', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T16:40:54.774247Z",
     "start_time": "2024-03-02T16:40:54.733387Z"
    }
   },
   "id": "e77bbc7675aa7cde",
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
