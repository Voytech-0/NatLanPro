{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:41:05.084265Z",
     "start_time": "2024-03-28T17:41:05.080597Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:41:05.120789Z",
     "start_time": "2024-03-28T17:41:05.117231Z"
    }
   },
   "id": "cd68bec60e2d33c0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:41:05.171495Z",
     "start_time": "2024-03-28T17:41:05.167991Z"
    }
   },
   "id": "ba66ac064b0e256d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# dependent on the implementation of the word2index and index2word\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 80 + 2 # 80 words + SOS and EOS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:41:05.201371Z",
     "start_time": "2024-03-28T17:41:05.197893Z"
    }
   },
   "id": "82cf8dea8a0ef552",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    \"\"\"Class to store the vocabulary of a language and the mappings between words and indices.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:41:05.230280Z",
     "start_time": "2024-03-28T17:41:05.223730Z"
    }
   },
   "id": "9d67c1ab9f525cc0",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def readLangs(to_spanish=False):\n",
    "    \"\"\"Reads the lines from the csv file and creates the Lang instances for the input and output languages, as well as the pairs of sentences.\"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the cvs file\n",
    "    file = pd.read_csv(\"../europarl-extract-master/corpora/cropped_europarl.csv\")\n",
    "    en = file[\"en\"]\n",
    "    es = file[\"es\"]\n",
    "\n",
    "    # Split every line into pairs\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if to_spanish:\n",
    "        pairs = list(zip(es, en))\n",
    "        input_lang = Lang(\"es\")\n",
    "        output_lang = Lang(\"en\")\n",
    "    else:\n",
    "        pairs = list(zip(en, es))\n",
    "        input_lang = Lang(\"en\")\n",
    "        output_lang = Lang(\"es\")\n",
    "        \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:41:05.319692Z",
     "start_time": "2024-03-28T17:41:05.314309Z"
    }
   },
   "id": "96ffffae0e32e967",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "('If there was ever a good reason for countries to ensure better accounting and forecasting, that was it', 'Si alguna vez ha habido una buena razón por la que los países deberían garantizar una contabilidad y unas previsiones mejores, ha sido esta')\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = readLangs()\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(random.choice(pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:07.601490Z",
     "start_time": "2024-03-28T17:41:05.370171Z"
    }
   },
   "id": "54cc264a49496945",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 Reading now what happened then, not even a year ago, it becomes clear that that first report was intended to do anything but serve the cause of truth or reform, as is maintained today, so much so that this second report - which, on the other hand, could have provided much more salient points - was commissioned with the precise mandate not to address specific cases, since there is no intention to follow up the offences detailed in this report\n"
     ]
    }
   ],
   "source": [
    "# print the max length of the sentences in words\n",
    "max_length = 0\n",
    "max_index = 0\n",
    "for i, pair in enumerate(pairs):\n",
    "    if len(pair[0].split(' ')) > max_length:\n",
    "        max_length = len(pair[0].split(' '))\n",
    "        max_index = i\n",
    "print(max_length, pairs[max_index][0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.435301Z",
     "start_time": "2024-03-28T17:43:07.603914Z"
    }
   },
   "id": "8687a5b384d95520",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return input_tensor, target_tensor\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = readLangs()\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.443132Z",
     "start_time": "2024-03-28T17:43:10.436688Z"
    }
   },
   "id": "5db01f9739ea2e5f",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, hidden = self.gru(self.dropout(self.embedding(x)))\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.451603Z",
     "start_time": "2024-03-28T17:43:10.447454Z"
    }
   },
   "id": "46add9dcb9923925",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_output)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        embedded_rel = F.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded_rel, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.459657Z",
     "start_time": "2024-03-28T17:43:10.453106Z"
    }
   },
   "id": "dba66bedbf53677c",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.468196Z",
     "start_time": "2024-03-28T17:43:10.461873Z"
    }
   },
   "id": "c8d9447474cef911",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, n_heads=8):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        self.attn = nn.MultiheadAttention(hidden_size, n_heads)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        query = query.transpose(0, 1)  # [batch_size, 1, hidden_size] -> [1, batch_size, hidden_size]\n",
    "        keys = keys.transpose(0, 1)    # [batch_size, seq_len, hidden_size] -> [seq_len, batch_size, hidden_size]\n",
    "        context, attn_weights = self.attn(query, keys, keys)\n",
    "        context = context.transpose(0, 1)  # [1, batch_size, hidden_size] -> [batch_size, 1, hidden_size]\n",
    "        return context, attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.475069Z",
     "start_time": "2024-03-28T17:43:10.470156Z"
    }
   },
   "id": "ffdbd78e1b4fa1e5",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, attention_type, dropout_p=0.1):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = attention_type\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.487994Z",
     "start_time": "2024-03-28T17:43:10.476827Z"
    }
   },
   "id": "b74c9a2d2452fa33",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "                decoder_optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    for data in tqdm(enumerate(i, dataloader), leave=False):\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            torch.save(encoder.state_dict(), \"encoder\"+i+\".pt\")\n",
    "            torch.save(decoder.state_dict(), \"decoder\"+i+\".pt\")\n",
    "            \n",
    "\n",
    "    return total_loss / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.497600Z",
     "start_time": "2024-03-28T17:43:10.489478Z"
    }
   },
   "id": "ba731c24fd7d868c",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.961106Z",
     "start_time": "2024-03-28T17:43:10.502790Z"
    }
   },
   "id": "9cbbf855683a1b1",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "          print_every=100, plot_every=100):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(print_loss_avg)\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.967359Z",
     "start_time": "2024-03-28T17:43:10.962813Z"
    }
   },
   "id": "d2e2531c3024840d",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.972953Z",
     "start_time": "2024-03-28T17:43:10.968789Z"
    }
   },
   "id": "d587f2b145c9606",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.977749Z",
     "start_time": "2024-03-28T17:43:10.974355Z"
    }
   },
   "id": "ed9a5f95af5f0fbc",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "epochs = 20"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:43:10.981271Z",
     "start_time": "2024-03-28T17:43:10.978872Z"
    }
   },
   "id": "bfbba7043b5c5a57",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:44:50.544481Z",
     "start_time": "2024-03-28T17:43:10.982493Z"
    }
   },
   "id": "53265495581a7bd2",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/60521 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 1/60521 [00:48<809:07:13, 48.13s/it]\u001B[A"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
    "# attention_type = BahdanauAttention(hidden_size)\n",
    "attention_type = MultiheadAttention(hidden_size, 8)\n",
    "decoder = AttnDecoder(hidden_size, output_lang.n_words, attention_type=attention_type).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, epochs, print_every=1000, plot_every=5000)\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder.pt\")\n",
    "torch.save(decoder.state_dict(), \"decoder.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-28T17:47:44.370753Z"
    }
   },
   "id": "1a4d87614ce5d31e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:47:03.478476Z",
     "start_time": "2024-03-28T17:47:03.478197Z"
    }
   },
   "id": "d0f895b7a76af20b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "139bf31a33bf3a31"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
