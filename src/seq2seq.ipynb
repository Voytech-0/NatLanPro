{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.0 from /Users/wojtek/Library/Mobile Documents/com~apple~CloudDocs/Documents/NLP/NLP_Assigmnent/.venv3.9/lib/python3.9/site-packages/pip (python 3.9)\r\n",
      "Python 3.9.18\r\n"
     ]
    }
   ],
   "source": [
    "!pip --version\n",
    "!python3 --version\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:15:56.623241Z",
     "start_time": "2024-04-03T17:15:55.859349Z"
    }
   },
   "id": "dbf212cd7fb0e7b",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "# import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:25.951645Z",
     "start_time": "2024-04-03T17:15:56.629361Z"
    }
   },
   "id": "40b4cdeb17e50fae",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:25.958406Z",
     "start_time": "2024-04-03T17:16:25.953690Z"
    }
   },
   "id": "e5501e2e791779d1",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:25.969484Z",
     "start_time": "2024-04-03T17:16:25.965056Z"
    }
   },
   "id": "6aa4c5024fbf21c2",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# dependent on the implementation of the word2index and index2word\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 80 + 2 # 80 words + SOS and EOS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:25.977582Z",
     "start_time": "2024-04-03T17:16:25.971929Z"
    }
   },
   "id": "d85afe0fbf5d1675",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    \"\"\"Class to store the vocabulary of a language and the mappings between words and indices.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:25.990863Z",
     "start_time": "2024-04-03T17:16:25.980846Z"
    }
   },
   "id": "e33fc6e94a751fe2",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def readLangs(to_spanish=True):\n",
    "    \"\"\"Reads the lines from the csv file and creates the Lang instances for the input and output languages, as well as the pairs of sentences.\"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the cvs file\n",
    "    file = pd.read_csv(\"../europarl-extract-master/corpora/cropped_europarl.csv\")\n",
    "    en = file[\"en\"]\n",
    "    es = file[\"es\"]\n",
    "\n",
    "    # Split every line into pairs\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if not to_spanish:\n",
    "        pairs = list(zip(es, en))\n",
    "        input_lang = Lang(\"es\")\n",
    "        output_lang = Lang(\"en\")\n",
    "    else:\n",
    "        pairs = list(zip(en, es))\n",
    "        input_lang = Lang(\"en\")\n",
    "        output_lang = Lang(\"es\")\n",
    "        \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:26.001910Z",
     "start_time": "2024-04-03T17:16:25.995451Z"
    }
   },
   "id": "13f114a653843ff2",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "('If there was ever a good reason for countries to ensure better accounting and forecasting, that was it', 'Si alguna vez ha habido una buena razón por la que los países deberían garantizar una contabilidad y unas previsiones mejores, ha sido esta')\n",
      "1936655\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = readLangs()\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(random.choice(pairs))\n",
    "print(len(pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:29:06.344395Z",
     "start_time": "2024-04-03T17:26:25.783270Z"
    }
   },
   "id": "5b7ce304b4ea8ef1",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return input_tensor, target_tensor\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = readLangs()\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:26.018586Z",
     "start_time": "2024-04-03T17:16:26.004943Z"
    }
   },
   "id": "162703a0cb7a00c4",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, hidden = self.gru(self.dropout(self.embedding(x)))\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:26.031056Z",
     "start_time": "2024-04-03T17:16:26.022668Z"
    }
   },
   "id": "a161818e6a7fd3a",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_output)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        embedded_rel = F.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded_rel, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:26.050806Z",
     "start_time": "2024-04-03T17:16:26.038210Z"
    }
   },
   "id": "9075eef1cc323a98",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:26.063648Z",
     "start_time": "2024-04-03T17:16:26.053051Z"
    }
   },
   "id": "f364865512adfa",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# just use torch multiheadAttention\n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, n_heads=8):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        self.attn = nn.MultiheadAttention(hidden_size, n_heads)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        query = query.transpose(0, 1)  # [batch_size, 1, hidden_size] -> [1, batch_size, hidden_size]\n",
    "        keys = keys.transpose(0, 1)    # [batch_size, seq_len, hidden_size] -> [seq_len, batch_size, hidden_size]\n",
    "        context, attn_weights = self.attn(query, keys, keys)\n",
    "        context = context.transpose(0, 1)  # [1, batch_size, hidden_size] -> [batch_size, 1, hidden_size]\n",
    "        return context, attn_weights\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:26.073770Z",
     "start_time": "2024-04-03T17:16:26.065561Z"
    }
   },
   "id": "20c94b32ec0380d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, attention_type, dropout_p=0.1):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = attention_type\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:26.093420Z",
     "start_time": "2024-04-03T17:16:26.079349Z"
    }
   },
   "id": "c86049a8161f27e3",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "                decoder_optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    for i, data in tqdm(enumerate( dataloader), leave=False):\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            torch.save(encoder.state_dict(), f\"encoder_{i}.pt\")\n",
    "            torch.save(decoder.state_dict(), f\"decoder_{i}.pt\")\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:26.107295Z",
     "start_time": "2024-04-03T17:16:26.098372Z"
    }
   },
   "id": "1ad60619be6fda3d",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:27.813690Z",
     "start_time": "2024-04-03T17:16:26.109750Z"
    }
   },
   "id": "bab58d5ece98b597",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "          print_every=100, plot_every=100):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.AdamW(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.AdamW(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(print_loss_avg)\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:27.822983Z",
     "start_time": "2024-04-03T17:16:27.815507Z"
    }
   },
   "id": "ea4e3124567b0663",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:16:27.835166Z",
     "start_time": "2024-04-03T17:16:27.825180Z"
    }
   },
   "id": "e34ab4866f381d2a",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:29:15.293088Z",
     "start_time": "2024-04-03T17:29:15.284862Z"
    }
   },
   "id": "85adbf7dbc67e5c2",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "epochs = 20\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:18:25.251502Z",
     "start_time": "2024-04-03T17:18:25.248032Z"
    }
   },
   "id": "e800753903ac1e28",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:20:36.791403Z",
     "start_time": "2024-04-03T17:18:25.462843Z"
    }
   },
   "id": "a3f02879f61db7fa",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m\n\u001B[0;32m      2\u001B[0m input_lang, output_lang, train_dataloader \u001B[38;5;241m=\u001B[39m get_dataloader(batch_size)\n\u001B[1;32m----> 4\u001B[0m encoder \u001B[38;5;241m=\u001B[39m \u001B[43mEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_lang\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      5\u001B[0m attention_type \u001B[38;5;241m=\u001B[39m BahdanauAttention(hidden_size)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#attention_type = MultiheadAttention(hidden_size, 4)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[9], line 5\u001B[0m, in \u001B[0;36mEncoder.__init__\u001B[1;34m(self, input_size, hidden_size, dropout)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28msuper\u001B[39m(Encoder, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size \u001B[38;5;241m=\u001B[39m hidden_size\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgru \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mGRU(hidden_size, hidden_size, batch_first\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mDropout(dropout)\n",
      "File \u001B[1;32m~\\Documents\\NLPMachineTranslation\\venv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:145\u001B[0m, in \u001B[0;36mEmbedding.__init__\u001B[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m Parameter(torch\u001B[38;5;241m.\u001B[39mempty((num_embeddings, embedding_dim), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfactory_kwargs),\n\u001B[0;32m    144\u001B[0m                             requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m _freeze)\n\u001B[1;32m--> 145\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(_weight\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m [num_embeddings, embedding_dim], \\\n\u001B[0;32m    148\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mShape of weight does not match num_embeddings and embedding_dim\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\NLPMachineTranslation\\venv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:154\u001B[0m, in \u001B[0;36mEmbedding.reset_parameters\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreset_parameters\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 154\u001B[0m     \u001B[43minit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormal_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fill_padding_idx_with_zero()\n",
      "File \u001B[1;32m~\\Documents\\NLPMachineTranslation\\venv\\lib\\site-packages\\torch\\nn\\init.py:175\u001B[0m, in \u001B[0;36mnormal_\u001B[1;34m(tensor, mean, std, generator)\u001B[0m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39moverrides\u001B[38;5;241m.\u001B[39mhas_torch_function_variadic(tensor):\n\u001B[0;32m    172\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39moverrides\u001B[38;5;241m.\u001B[39mhandle_torch_function(\n\u001B[0;32m    173\u001B[0m         normal_, (tensor,), tensor\u001B[38;5;241m=\u001B[39mtensor, mean\u001B[38;5;241m=\u001B[39mmean, std\u001B[38;5;241m=\u001B[39mstd, generator\u001B[38;5;241m=\u001B[39mgenerator\n\u001B[0;32m    174\u001B[0m     )\n\u001B[1;32m--> 175\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_no_grad_normal_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\NLPMachineTranslation\\venv\\lib\\site-packages\\torch\\nn\\init.py:20\u001B[0m, in \u001B[0;36m_no_grad_normal_\u001B[1;34m(tensor, mean, std, generator)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_no_grad_normal_\u001B[39m(tensor, mean, std, generator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 20\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormal_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
    "attention_type = BahdanauAttention(hidden_size)\n",
    "#attention_type = MultiheadAttention(hidden_size, 4)\n",
    "decoder = AttnDecoder(hidden_size, output_lang.n_words, attention_type=attention_type).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, epochs, print_every=1000, plot_every=5000)\n",
    "\n",
    "torch.save(encoder.state_dict(), \"encoder.pt\")\n",
    "torch.save(decoder.state_dict(), \"decoder.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:50:25.402149100Z",
     "start_time": "2024-03-31T09:50:24.684429100Z"
    }
   },
   "id": "6dcaea0fd6eec48d",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
    "attention_type = BahdanauAttention(hidden_size)\n",
    "decoder = AttnDecoder(hidden_size, output_lang.n_words, attention_type=attention_type).to(device)\n",
    "encoder.load_state_dict(torch.load(\"../data/results_bahdau/encoder_partial.pt\", map_location=device))\n",
    "decoder.load_state_dict(torch.load(\"../data/results_bahdau/decoder_partial.pt\", map_location=device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:22:04.389131Z",
     "start_time": "2024-04-03T17:22:02.045443Z"
    }
   },
   "id": "905ce6e51685f42e",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> It perceives the Union' s sustainable development to be the efficiency of markets, goods, services, capital and employment\n",
      "= Para ella, el desarrollo duradero de la Unión es la eficacia de los mercados, de los bienes, de los servicios, de los capitales y del trabajo\n",
      "< la eficacia de los mercados, bienes, servicios, capital y empleo <EOS>\n",
      "\n",
      "> A huge sum, although it remains within the agreed 20% of the estimate for all European institutions put together\n",
      "= Una suma astronómica, aunque no sobrepasa el 20% de la estimación acordada para el conjunto de todas las instituciones europeas\n",
      "< en el acuerdo acordado del 20 % de las previsiones de todas las instituciones europeas que juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos juntos <EOS>\n",
      "\n",
      "> The central idea of this pact is that countries which get into economic problems should be fined\n",
      "= Lo esencial de este pacto es que los países que tengan problemas económicos se verán castigados con sanciones\n",
      "< es que los países que se encuentran en problemas económicos deben ser castigados por delitos económicos <EOS>\n",
      "\n",
      "> On closer inspection, however, it unfortunately becomes apparent that ‘old boy networks’ still operate in many of these Balkan states\n",
      "= No obstante, si se analiza más de cerca la situación, se puede apreciar, por desgracia, que en muchos de estos Estados balcánicos sigue funcionando el «amiguismo\n",
      "< por desgracia se ha visto que el trabajo de los trabajadores siguen siendo aún más en muchos de los Estados de los Estados balcánicos <EOS>\n",
      "\n",
      "> There is also the matter of the unfair advantages granted to the eastern German\n",
      "= Tenemos igualmente la cuestión de las injustas ventajas concedidas a los Estados federados de Alemania Oriental\n",
      "< al respecto a la Presidencia alemana Oriental <EOS>\n",
      "\n",
      "> They increase the level of exploitation of the working class and maximise the profits of big business\n",
      "= De este modo, podrán aumentar el nivel de explotación de la clase trabajadora y generar más beneficios para las grandes empresas\n",
      "< de la clase trabajadora y maximizar los beneficios de las grandes empresas empresariales grandes de las grandes empresas empresariales <EOS>\n",
      "\n",
      "> We have witnessed the assassination of two ministers and this week a bomb attack, presumably aimed against western forces\n",
      "= Hemos sido testigos del asesinato de dos ministros, y esta semana ha habido un atentado con explosivos, presumiblemente dirigido contra las fuerzas occidentales\n",
      "< y de esta semana un ataque bomba con el que se opone a las fuerzas occidentales occidentales <EOS>\n",
      "\n",
      "> Only last week I launched a brilliant LEADER II project in a small place called Swanton Morley where all levels of the public and private sectors have come together to benefit the hard-pressed village\n",
      "= La semana pasada sin ir más lejos inauguré un brillante proyecto de LEADER II en un pequeño lugar llamado Swanton Morley, donde todas las instancias de los sectores público y privado se han unido para beneficiar a un pueblo que atraviesa grandes dificultades\n",
      "< en el que se lanzó un proyecto LEADER II en un pequeño lugar llamado a la hora de que el país de los sectores públicos y privados se han beneficiado de beneficiar a la población europea <EOS>\n",
      "\n",
      "> Hatzidakis report (A5-0344/2001\n",
      "= Informe Hatzidakis (A5-0344/2001\n",
      "< el informe de Berlín - (CS) sistemas de asociación - sistemas de asociación <EOS>\n",
      "\n",
      "> The 'Brussels consensus' is the blind, roughshod application of neoliberal dogma: squeezing public services and the welfare state; wage austerity and minimal regulation of the financial markets\n",
      "= El consenso de Bruselas es la aplicación ciega y sin miramientos de un dogma neoliberal: explotación de los servicios públicos y el Estado social; austeridad en los salarios y mínima regulación de los mercados financieros\n",
      "< los Estados Unidos se aplican a los servicios de la neoliberales y los derechos de los gastos del bienestar salarial y la regulación mínima de los mercados financieros <EOS>\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:29:34.824913Z",
     "start_time": "2024-04-03T17:29:19.017368Z"
    }
   },
   "id": "d001f1d0f55381e8",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating BLEU Score:   0%|          | 100/1936655 [02:24<778:04:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 3.99967114868466e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def bleuScore(encoder, decoder, input_lang, output_lang, train_dataloader):\n",
    "    \n",
    "    total_score = 0.0\n",
    "    with tqdm(total=len(pairs), desc=\"Calculating BLEU Score\") as pbar:\n",
    "        for pair in pairs[0:100]:\n",
    "            input_sentence = pair[0]\n",
    "            target_sentence = pair[1]\n",
    "            output_words, _ = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "            output_sentence = ' '.join(output_words)\n",
    "            bleu = sentence_bleu([target_sentence.split()], output_sentence.split())\n",
    "            total_score += bleu\n",
    "            pbar.update(1)\n",
    "    average_bleu = total_score / len(pairs)\n",
    "    print('Average BLEU Score:', average_bleu)\n",
    "\n",
    "bleuScore(encoder, decoder, input_lang, output_lang, pairs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:33:10.495129Z",
     "start_time": "2024-04-03T17:30:45.840210Z"
    }
   },
   "id": "4214dc1d98e3084e",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d65e29e305f9a2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
